{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Mgpci_UotUVl"},"outputs":[],"source":["# !unzip /content/drive/MyDrive/gender_dataset_face-20220319T023558Z-001.zip -d /content/drive/MyDrive/gender_dataset_face"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bVVlsIbLVRyb"},"outputs":[],"source":["import os\n","os.makedirs(\"Model_weights\", exist_ok=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47FQgndsUehK"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"z94GVpdgmbZz"},"outputs":[],"source":["from keras.models import Sequential\n","from tensorflow.keras.layers import BatchNormalization\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Activation\n","from keras.layers import Flatten\n","\n","from keras.layers import Dropout\n","from keras.layers import Dense\n","from tensorflow.keras import datasets, layers, models\n","from keras import backend as K\n","from keras import models\n","from keras.applications.vgg16 import VGG16\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rLwedq3AmoSt"},"outputs":[],"source":["class SmallerVGGNet:\n","    @staticmethod\n","    def vgg_net(width, height, depth, classes):\n","\n","            conv_base = VGG16(weights='imagenet',\n","                          include_top=False,\n","                          input_shape=(height, width, depth))\n","            model = models.Sequential()\n","\n","            model.add(conv_base)\n","            model.add(Flatten())\n","\n","            model.add(Dense(1024, activation='relu'))\n","            model.add(BatchNormalization())\n","            model.add(Dropout(0.5))\n","            model.add(Dense(classes, activation='sigmoid'))\n","            return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YnSXYlVgoEbN"},"outputs":[],"source":["import matplotlib\n","matplotlib.use(\"Agg\")  # Only needed in headless environments like servers\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import random\n","import cv2\n","import os\n","import glob\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n","from tensorflow.keras.utils import img_to_array, to_categorical, plot_model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","\n","# If you have a custom model, make sure the import is correct\n","# from model.smallervggnet import SmallerVGGNet  # Uncomment if you have this file and model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"b6Qp_KIiWp-u"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","class SmallerVGGNet:\n","    @staticmethod\n","    def build(width, height, depth, classes):\n","        model = Sequential()\n","\n","        # First CONV => RELU => POOL layer\n","        model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(height, width, depth)))\n","        model.add(MaxPooling2D(pool_size=(3, 3)))\n","\n","        # Second CONV => RELU => POOL layer\n","        model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","        # Third CONV => RELU => POOL layer\n","        model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","        # Flatten and add Fully Connected layers\n","        model.add(Flatten())\n","        model.add(Dense(256, activation=\"relu\"))\n","        model.add(Dropout(0.5))  # Prevent overfitting\n","        model.add(Dense(classes, activation=\"softmax\"))  # Output layer\n","\n","        return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":493561,"status":"ok","timestamp":1739592755183,"user":{"displayName":"Manann Solanky","userId":"08824588116014492682"},"user_tz":-330},"id":"7wKk0N5WnXDk","outputId":"222cff64-6a86-4c7a-ae6b-e62a14da5a9f"},"outputs":[{"ename":"ValueError","evalue":"With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-407b9667929f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# split dataset for training and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m trainX, testX, trainY, testY = train_test_split(data, labels, test_size=0.2,\n\u001b[0m\u001b[1;32m     41\u001b[0m                                                   random_state=2)\n\u001b[1;32m     42\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."]}],"source":["import glob\n","import os\n","import random\n","epochs = 50\n","lr = 1e-3\n","batch_size = 32\n","img_dims = (96,96,3)\n","\n","data = []\n","labels = []\n","\n","# load image files from the dataset\n","image_files = [f for f in glob.glob('/content/drive/MyDrive/gender_dataset_face/gender_dataset_face' + \"/**/*\", recursive=True)\n","if not os.path.isdir(f)]\n","random.seed(42)\n","random.shuffle(image_files)\n","\n","# create groud-truth label from the image path\n","for img in image_files:\n","\n","    image = cv2.imread(img)\n","    # print(img)\n","    image = cv2.resize(image, (96,96))\n","    image = img_to_array(image)\n","    data.append(image)\n","\n","    label = img.split(os.path.sep)[-2]\n","    if label == \"woman\":\n","        label = 1\n","    else:\n","        label = 0\n","\n","    labels.append([label])\n","\n","# pre-processing\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","\n","# split dataset for training and validation\n","trainX, testX, trainY, testY = train_test_split(data, labels, test_size=0.2,\n","                                                  random_state=2)\n","trainY = to_categorical(trainY, num_classes=2)\n","testY = to_categorical(testY, num_classes=2)\n","\n","# augmenting datset\n","aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n","                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n","                         horizontal_flip=True, fill_mode=\"nearest\")\n","\n","# build model\n","# model = SmallerVGGNet.build(width=img_dims[0], height=img_dims[1], depth=img_dims[2],\n","#                             classes=2)\n","model = SmallerVGGNet.vgg_net(width=img_dims[0], height=img_dims[1], depth=img_dims[2],\n","                            classes=2)\n","\n","# compile the model\n","opt = Adam(learning_rate=lr, decay=lr / epochs)\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","#checkpoint save\n","filepath=\"/content/epochs:{epoch:03d}-val_accuracy:{val_accuracy:.3f}.h5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]\n","# model.load_model(\"Model_weights/epochs:009-val_accuracy:0.797.hdf5\")\n","\n","# train the model\n","history = model.fit(aug.flow(trainX, trainY, batch_size=batch_size),\n","                        validation_data=(testX,testY),\n","                        steps_per_epoch=len(trainX) // batch_size,\n","                        epochs=epochs, verbose=1,callbacks=callbacks_list)\n","# model.load_weights(\"Model_weights/epochs:{epoch:03d}-val_accuracy:{val_accuracy:.3f}.hdf5\")\n","\n","# save the model to disk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44877,"status":"ok","timestamp":1744106136885,"user":{"displayName":"Hemant Chauthe","userId":"12252838119456289894"},"user_tz":-330},"id":"7lf0hTbYUgVY","outputId":"45aa09e9-a089-4c17-e463-246423702c74"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kHoykW2tnn3G"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","# plt.savefig('/content/drive/My Drive/Interface_model/result.plot')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"_CIJV44syhrv"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ymqKlitRpQFt"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","pred = model.predict(testX)\n","pred = np.argmax(pred,axis = 1)\n","y_true = np.argmax(testY,axis = 1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"63kb2nK_pTUG"},"outputs":[],"source":["CM = confusion_matrix(y_true, pred)\n","from mlxtend.plotting import plot_confusion_matrix\n","fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n","# plt.show()\n","fig"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hVZvSg1xpayp"},"outputs":[],"source":["!pip install cvlib"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"g3pmgQeypXct"},"outputs":[],"source":["# from keras.preprocessing.image import img_to_array\n","from tensorflow.keras.utils import img_to_array\n","\n","from keras.models import load_model\n","# from keras.utils import get_file\n","import numpy as np\n","import argparse\n","import cv2\n","import os\n","!pip install cvlib\n","import cvlib as cv"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4k8_2RNyrDtb"},"outputs":[],"source":["img= '/content/drive/MyDrive/men.jpg'\n","image = cv2.imread(img)\n","# cv2.imread('/conte')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZBpE52ruM1No"},"outputs":[],"source":["image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Data Science batch.jpg')\n","\n","if image is None:\n","    print(\"Could not read input image\")\n","    exit()\n","\n","# load pre-trained model\n","model = load_model(\"/content/drive/MyDrive/Colab Notebooks/epochs_044-val_accuracy_0.966.keras\")\n","\n","# detect faces in the image\n","face, confidence = cv.detect_face(image)\n","\n","classes = ['man','woman']\n","# loop through detected faces\n","for idx, f in enumerate(face):\n","\n","     # get corner points of face rectangle\n","    (startX, startY) = f[0], f[1]\n","    (endX, endY) = f[2], f[3]\n","\n","    # draw rectangle over face\n","    cv2.rectangle(image, (startX,startY), (endX,endY), (0,255,0), 2)\n","\n","    # crop the detected face region\n","    face_crop = np.copy(image[startY:endY,startX:endX])\n","\n","    # preprocessing for gender detection model\n","    face_crop = cv2.resize(face_crop,(96,96))\n","    face_crop = face_crop.astype(\"float\") / 255.0\n","    face_crop = img_to_array(face_crop)\n","    face_crop = np.expand_dims(face_crop, axis=0)\n","\n","    # apply gender detection on face\n","    conf = model.predict(face_crop)[0]\n","    print(conf)\n","    print(classes)\n","\n","    # get label with max accuracy\n","    idx = np.argmax(conf)\n","    label = classes[idx]\n","\n","    label = \"{}: {:.2f}%\".format(label, conf[idx] * 100)\n","\n","    Y = startY - 10 if startY - 10 > 10 else startY + 10\n","\n","    # write label and confidence above face rectangle\n","    if conf[idx] * 100 > 50.0:\n","        cv2.putText(image, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX,\n","                0.7, (0, 255, 0), 1)\n","# cv2.imwrite('/content/',image)\n","# display output\n","# cv2.imshow(\"gender detection\", image)\n","\n","# # press any key to close window\n","# cv2.waitKey(0)\n","\n","# # save output\n","cv2.imwrite(\"gender_detection.jpg\", image)\n","\n","# # release resources\n","# cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PqBXxrJQ90A4"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1RJyhKVCsnezrzaC_So7WuYWVTdHb29ta","timestamp":1744107361885}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}